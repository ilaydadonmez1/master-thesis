{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec896eec-7aac-41ad-aac0-05515abfe2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from random import gauss\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c37c450c-b40f-4a8d-a4f4-51ace7590e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to read a CSV file as a binary matrix\n",
    "def read_csv_as_binary_matrix(file_path):\n",
    "    df = pd.read_csv(file_path, header=None, delimiter=\";\", dtype=int)\n",
    "    return df.values\n",
    "\n",
    "# Define functions for calculating aggregated matrices\n",
    "def calculate_aggregated_matrix_2x2(original_matrix):\n",
    "    num_rows, num_cols = original_matrix.shape\n",
    "    aggregated_matrix = np.zeros((num_rows // 2, num_cols // 2), dtype=float)\n",
    "\n",
    "    for i in range(0, num_rows, 2):\n",
    "        for j in range(0, num_cols, 2):\n",
    "            square = original_matrix[i:i + 2, j:j + 2]\n",
    "            average = square.mean()\n",
    "            row_idx = i // 2\n",
    "            col_idx = j // 2\n",
    "            aggregated_matrix[row_idx, col_idx] = round(average, 2)\n",
    "\n",
    "    return aggregated_matrix\n",
    "\n",
    "def calculate_aggregated_matrix_3x3(original_matrix):\n",
    "    num_rows, num_cols = original_matrix.shape\n",
    "    aggregated_matrix = np.zeros((num_rows // 3, num_cols // 3), dtype=float)\n",
    "\n",
    "    for i in range(0, num_rows, 3):\n",
    "        for j in range(0, num_cols, 3):\n",
    "            square = original_matrix[i:i + 3, j:j + 3]\n",
    "            average = square.mean()\n",
    "            row_idx = i // 3\n",
    "            col_idx = j // 3\n",
    "            aggregated_matrix[row_idx, col_idx] = round(average, 2)\n",
    "\n",
    "    return aggregated_matrix\n",
    "\n",
    "def calculate_aggregated_matrix_4x4(original_matrix):\n",
    "    num_rows, num_cols = original_matrix.shape\n",
    "    aggregated_matrix = np.zeros((num_rows // 4, num_cols // 4), dtype=float)\n",
    "\n",
    "    for i in range(0, num_rows, 4):\n",
    "        for j in range(0, num_cols, 4):\n",
    "            square = original_matrix[i:i + 4, j:j + 4]\n",
    "            average = square.mean()\n",
    "            row_idx = i // 4\n",
    "            col_idx = j // 4\n",
    "            aggregated_matrix[row_idx, col_idx] = round(average, 2)\n",
    "\n",
    "    return aggregated_matrix\n",
    "\n",
    "def calculate_betas(aggregated_matrix, Sigma):\n",
    "    element_num = aggregated_matrix.shape[0]\n",
    "    interaction_coeffi1 = np.zeros((element_num, element_num))\n",
    "    interaction_coeffi2 = np.zeros((element_num, element_num))\n",
    "\n",
    "    for i in range(element_num):\n",
    "       # Sigma1 = np.random.normal(0, 1)  # Random Sigma for coefficient 1\n",
    "        interaction_coeffi1[0, i] = np.exp(-abs(gauss(aggregated_matrix[i,i], Sigma)))\n",
    "\n",
    "        for j in range(element_num):\n",
    "            if i != j:  # Avoid self-interaction\n",
    "                #  Sigma2 = np.random.normal(0, 1)  # Random Sigma for coefficient 2\n",
    "                interaction_coeffi2[i, j] = np.exp(-abs(gauss(aggregated_matrix[i,j], Sigma)))\n",
    "\n",
    "    return interaction_coeffi1, interaction_coeffi2\n",
    "\n",
    "def calculate_fitness(X, interaction_coeffi1, interaction_coeffi2, aggregated_matrix):\n",
    "    element_num = aggregated_matrix.shape[0]\n",
    "    fitness = 0.0\n",
    "\n",
    "    for i in range(element_num):\n",
    "        fitness += interaction_coeffi1[0, i] * X[i]\n",
    "        for j in range(element_num):\n",
    "            if i != j:\n",
    "                fitness += interaction_coeffi2[i, j] * X[i] * X[j]\n",
    "\n",
    "    return fitness\n",
    "\n",
    "def generate_landscape(n, aggregated_matrix, interaction_coeffi1, interaction_coeffi2):\n",
    "    fitness_vec = []\n",
    "    fitness_pos = []\n",
    "\n",
    "    for rr in range(pow(2,n)):\n",
    "        # Convert rr to binary format and pad it to the desired length\n",
    "        binary_vector = format(rr, f'0{n}b')\n",
    "        bin_vec = binary_vector\n",
    "        position_11 = int(bin_vec, 2)\n",
    "        fitness_pos.append(position_11)\n",
    "        binary_vector = ','.join(binary_vector)\n",
    "\n",
    "        # Replace 0 with -1\n",
    "        binary_vector = binary_vector.replace('0', '-1')\n",
    "\n",
    "        # Convert the binary string to a list of integers\n",
    "        X = [int(x) for x in binary_vector.split(\",\")]\n",
    "\n",
    "        # Call calculate_fitness\n",
    "        fitness = calculate_fitness(X, interaction_coeffi1, interaction_coeffi2, aggregated_matrix)\n",
    "        fitness_vec.append(fitness)\n",
    "\n",
    "        #print(f'Fitness for X={X}: {fitness}')\n",
    "        #print(\"Interaction Coefficients (1):\")\n",
    "        #print(interaction_coeffi1)\n",
    "        #print(\"\\nInteraction Coefficients (2):\")\n",
    "        #print(interaction_coeffi2)\n",
    "\n",
    "    return fitness_vec, fitness_pos\n",
    "\n",
    "def local_optima(fitness_vector, fitness_pos, Sigma, landscape_id, file_name):\n",
    "    local_optima_results = []\n",
    "    count_local_optima = 0\n",
    "\n",
    "    for i in range(len(fitness_vector)):\n",
    "        binary_vector = format(fitness_pos[i], f'0{n}b')\n",
    "        binary_vector = binary_vector.replace('-1', '0')\n",
    "        position_11 = int(binary_vector, 2)\n",
    "        index_position_11 = fitness_pos.index(position_11)\n",
    "        fitness_local = fitness_vector[index_position_11]\n",
    "        is_local_optima = True\n",
    "\n",
    "        for j in range(len(binary_vector)):\n",
    "            neighbor_binary_vector_11 = list(binary_vector)\n",
    "\n",
    "            if neighbor_binary_vector_11[j-1] == '0':\n",
    "                neighbor_binary_vector_11[j-1] = '1'\n",
    "            else:\n",
    "                neighbor_binary_vector_11[j-1] = '0'\n",
    "\n",
    "            #print(\"binary_vector, neighbor_binary_vector\",binary_vector, neighbor_binary_vector_11)\n",
    "\n",
    "            neighbor_binary_vector = ''.join(neighbor_binary_vector_11)\n",
    "            neighbor_binary_vector = neighbor_binary_vector.replace('-1', '0')\n",
    "            position_11 = int(neighbor_binary_vector, 2)\n",
    "            #print(\"position_11, fitness_pos\",position_11, fitness_pos)\n",
    "            index_position_11 = fitness_pos.index(position_11)\n",
    "            #print(\"index_position_11\",index_position_11)\n",
    "            neighbor_fitness_local = fitness_vector[index_position_11]\n",
    "            #print(\"neighbor_fitness_local, fitness_local\",neighbor_fitness_local, fitness_local)\n",
    "\n",
    "            if neighbor_fitness_local > fitness_local:\n",
    "                is_local_optima = False\n",
    "\n",
    "\n",
    "        if is_local_optima == True:\n",
    "            count_local_optima += 1\n",
    "\n",
    "        local_optima_results.append((landscape_id, Sigma, i + 1, count_local_optima, neighbor_fitness_local, fitness_local,file_name))\n",
    "\n",
    "    local_optima_df = pd.DataFrame(local_optima_results,\n",
    "                                   columns=['Landscape ID', 'Sigma', 'Count', 'Count Local Optima','Neighbor_fitness_local', 'Fitness_local','File Name'])\n",
    "\n",
    "\n",
    "    return local_optima_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9255b854-0133-4053-a8a9-e9f3061ab340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "padding_value = 0\n",
    "\n",
    "landscape_count = 500\n",
    "\n",
    "# Folder path where CSV files are located\n",
    "folder_path = \"/Users/ilaydadonmez/Desktop/R/DSM - CSV Files\"\n",
    "\n",
    "file_names = [\n",
    "    \"DSM-6\", \"DSM-48\", \"DSM-53\", \"DSM-57\", \"DSM-2\", \"DSM-3\", \"DSM-4\", \"DSM-14\", \"DSM-19\", \"DSM-20\", \"DSM-21\", \"DSM-22\", \"DSM-63\",\n",
    "    \"DSM-24\", \"DSM-42\", \"DSM-62\", \"DSM-31\", \"DSM-40\", \"DSM-39\", \"DSM-27\", \"DSM-9\", \"DSM-8\", \"DSM-26\", \"DSM-59\",  \"DSM-38\", \"DSM-7\",\n",
    "    \"DSM-33\", \"DSM-10\", \"DSM-60\", \"DSM-15\", \"DSM-11\", \"DSM-29\", \"DSM-13\", \"DSM-12\", \"DSM-47\", \"DSM-45\", \"DSM-41\", \"DSM-61\", \"DSM-28.2\",\n",
    "    \"DSM-28.1\", \"random_0\", \"hierarc\", \"block\", \"local\"]\n",
    "\n",
    "# Create a list of Sigma values for the 5 landscapes\n",
    "sigma_values = [5, 10, 15, 20, 25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "439253b9-987c-4a74-b48b-fcd43a9b7ea4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 44/44 [58:37:13<00:00, 4796.21s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store results for all landscapes and Sigmas\n",
    "detailed_results = []\n",
    "all_results = []\n",
    "dsm_info = []\n",
    "\n",
    "for file_name in tqdm(file_names):\n",
    "    file_path = os.path.join(folder_path, file_name + \".csv\")\n",
    "    binary_matrix = read_csv_as_binary_matrix(file_path) * 5\n",
    "    \"\"\"\n",
    "    # Print the original matrix and its size\n",
    "    print(f\"\\nOriginal DSM for {file_name}:\")\n",
    "    for row in binary_matrix:\n",
    "        print(\" \".join(map(str, row)))\n",
    "    #print(f\"Original Matrix Size: {binary_matrix.shape}\")\n",
    "    \"\"\"\n",
    "    # Check the size of the original matrix\n",
    "    num_rows, num_cols = binary_matrix.shape\n",
    "\n",
    "    if 18 <= num_rows <= 26 and 18 <= num_cols <= 26:\n",
    "        method = \"2x2\"\n",
    "        # Use 2x2 aggregation for matrix sizes between 18 and 26\n",
    "        if num_rows % 2 != 0:\n",
    "            # If not divisible by 2, add one row and one column filled with the specified padding value\n",
    "            binary_matrix = np.pad(binary_matrix, [(0, 1), (0, 1)], constant_values=padding_value)\n",
    "        aggregated_matrix = calculate_aggregated_matrix_2x2(binary_matrix)\n",
    "    elif 27 <= num_rows <= 39 and 27 <= num_cols <= 39:\n",
    "        method = \"3x3\"\n",
    "        # Use 3x3 aggregation for matrix sizes between 27 and 39\n",
    "        while num_rows % 3 != 0:\n",
    "            # Add one row and one column filled with the specified padding value until it's divisible by 3\n",
    "            binary_matrix = np.pad(binary_matrix, [(0, 1), (0, 1)], constant_values=padding_value)\n",
    "            num_rows, num_cols = binary_matrix.shape\n",
    "        aggregated_matrix = calculate_aggregated_matrix_3x3(binary_matrix)\n",
    "    elif 40 <= num_rows <= 57 and 40 <= num_cols <= 57:\n",
    "        method = \"4x4\"\n",
    "        # Use 4x4 aggregation for matrix sizes between 40 and 57\n",
    "        while num_rows % 4 != 0:\n",
    "            # Add one row and one column filled with the specified padding value until it's divisible by 4\n",
    "            binary_matrix = np.pad(binary_matrix, [(0, 1), (0, 1)], constant_values=padding_value)\n",
    "            num_rows, num_cols = binary_matrix.shape\n",
    "        aggregated_matrix = calculate_aggregated_matrix_4x4(binary_matrix)\n",
    "    elif num_rows == 12:\n",
    "        method = \"None\"\n",
    "        aggregated_matrix = binary_matrix\n",
    "    else:\n",
    "        # Handle other cases or raise an error\n",
    "        raise ValueError(\"Unsupported matrix size\")\n",
    "    \n",
    "    # Create a graph from the aggregated matrix\n",
    "    G = nx.Graph(aggregated_matrix)\n",
    "\n",
    "    # Find communities using the Louvain method\n",
    "    communities = list(nx.community.asyn_lpa_communities(G, weight='weight'))\n",
    "\n",
    "    # Calculate modularity for the communities\n",
    "    modularity = nx.community.quality.modularity(G, communities)\n",
    "    dsm_info.append((file_name,modularity,num_rows, binary_matrix.shape[0] , aggregated_matrix.shape[0], method))\n",
    "\n",
    "    for Sigma in sigma_values:\n",
    "        landscapes_results = []  # To store results for 5 landscapes for each Sigma\n",
    "        for landscape_id in range(landscape_count):\n",
    "            [interaction_coeffi1, interaction_coeffi2] = calculate_betas(aggregated_matrix, Sigma)\n",
    "            n = len(aggregated_matrix)\n",
    "            fitness_vector, fitness_pos = generate_landscape(n, aggregated_matrix, interaction_coeffi1,\n",
    "                                                             interaction_coeffi2)\n",
    "            local_optima_results = local_optima(fitness_vector, fitness_pos, Sigma, landscape_id, file_name)\n",
    "            landscapes_results.append(local_optima_results)\n",
    "\n",
    "        # Concatenate results for landscapes into one dataframe\n",
    "        landscapes_df = pd.concat(landscapes_results, ignore_index=True)\n",
    "        # Get only the last row for each landscape_id\n",
    "        landscapes_df = landscapes_df.groupby('Landscape ID').tail(1)\n",
    "        #print(landscapes_df)\n",
    "        # Append detailed information for this Sigma\n",
    "\n",
    "        all_results.append({'Sigma': Sigma, 'Landscapes DataFrame': landscapes_df, 'ID': len(all_results) + 1})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "822caf39-8fc0-49da-a5b6-d58814a6e99a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "dsm_info_df = pd.DataFrame(dsm_info,columns=['File Name','Modularity', 'Original Size', 'Modified Size','Aggregated Size', 'Method'])\n",
    "# Create a detailed summary dataframe\n",
    "detailed_summary_df = pd.concat([detailed_result['Landscapes DataFrame'] for detailed_result in all_results], ignore_index=True)\n",
    "\n",
    "detailed_summary_df = detailed_summary_df.drop(['Neighbor_fitness_local', 'Fitness_local', 'Landscape ID','Count'], axis = 1)\n",
    "\n",
    "# Group by 'File Name' and 'Sigma' and calculate max and mean separately\n",
    "max_values = detailed_summary_df.groupby([\"File Name\", \"Sigma\"])['Count Local Optima'].max().reset_index()\n",
    "mean_values = detailed_summary_df.groupby([\"File Name\", \"Sigma\"])['Count Local Optima'].mean().reset_index()\n",
    "\n",
    "# Merge the max and mean values\n",
    "detailed_summary_df = pd.merge(max_values, mean_values, on=[\"File Name\", \"Sigma\"], suffixes=('_Max', '_Mean'))\n",
    "\n",
    "# Rename columns for clarity\n",
    "detailed_summary_df.columns = ['File Name', 'Sigma', 'Max Count Local Optima', 'Mean Count Local Optima']\n",
    "\n",
    "#print(detailed_summary_df)\n",
    "\n",
    "# Save the detailed summary dataframe to a CSV file\n",
    "detailed_summary_csv_file_path = '/Users/ilaydadonmez/Desktop/detailed_summary_results.csv'\n",
    "detailed_summary_df.to_csv(detailed_summary_csv_file_path, index=False)\n",
    "\n",
    "# Concatenate all landscape results for all Sigmas into one dataframe\n",
    "all_results_pd = pd.concat([detailed_result['Landscapes DataFrame'] for detailed_result in all_results], ignore_index=True)\n",
    "\n",
    "# Save all results to a single CSV file\n",
    "all_results_csv_file_path = '/Users/ilaydadonmez/Desktop/all_results.csv'\n",
    "all_results_pd.to_csv(all_results_csv_file_path, index=False)\n",
    "\n",
    "dsm_info_csv_file_path = '/Users/ilaydadonmez/Desktop/dsm_info.csv'\n",
    "dsm_info_df.to_csv(dsm_info_csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0cdbe5ec-fe90-424e-9e91-acabc5e4486e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Sigma</th>\n",
       "      <th>Max Count Local Optima</th>\n",
       "      <th>Mean Count Local Optima</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DSM-10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DSM-10</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>5.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DSM-10</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>6.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DSM-10</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>7.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DSM-10</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>7.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>random_0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>random_0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>4.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>random_0</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>5.294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>random_0</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>5.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>random_0</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>5.544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    File Name  Sigma  Max Count Local Optima  Mean Count Local Optima\n",
       "0      DSM-10      5                      10                    3.184\n",
       "1      DSM-10     10                      20                    5.728\n",
       "2      DSM-10     15                      28                    6.940\n",
       "3      DSM-10     20                      24                    7.976\n",
       "4      DSM-10     25                      32                    7.904\n",
       "..        ...    ...                     ...                      ...\n",
       "215  random_0      5                       8                    3.034\n",
       "216  random_0     10                      16                    4.620\n",
       "217  random_0     15                      16                    5.294\n",
       "218  random_0     20                      16                    5.500\n",
       "219  random_0     25                      16                    5.544\n",
       "\n",
       "[220 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaf48e3-d282-42e5-b568-31779cb2ab05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601c08d5-ea7f-4026-972d-af58c5ab65cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf20e46-a2be-4e7b-8000-288068984b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
